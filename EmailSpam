import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split as tts
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, precision_score, recall_score , confusion_matrix, classification_report
import pandas as pd

# Importing file
data=pd.read_csv(r"C://Users//SHRI//Downloads//Dataset Titanic//spam.csv",encoding="ISO-8859-1") 

data

data.columns

data.info() 

data.drop(labels=['Unnamed: 3', 'Unnamed: 4'], axis=1) 
data.isna().sum() 

data['v1'] = data.v1.map({'ham' : 0, 'spam' : 1}) 

count_Class = pd.value_counts(data.v1, sort = True)

# Data to Plot
v1 = 'NotSpam', 'Spam'
sizes = [count_Class[0], count_Class[1]]
colors = ['green', 'red']
explode = (0.1, 0.1) 

plt.pie(sizes, explode = explode, labels = v1, colors = colors, autopct = '%1.1f%%', shadow = True, startangle = 90)
plt.axis('equal')
plt.show()
# Spliting the data into test and train sets
X_train, X_test, y_train, y_test = tts(data['v2'], data['v1'], test_size=0.2, random_state=1)

# Vectorizing the data
count_vector = CountVectorizer()
train_data = count_vector.fit_transform(X_train)
test_data = count_vector.transform(X_test)

Mnb = MultinomialNB()
Mnb.fit(train_data, y_train) 

# Now we predict
MnbPredicts = Mnb.predict(test_data) 
print("The accuracy of our Naïve Bayes multinomial model is {} %".format(accuracy_score(y_test, MnbPredicts) * 100))
print("The Precision of our Naïve Bayes multinomial model is {} %". format(precision_score(y_test, MnbPredicts)* 100))
print("The Recall of our Naïve Bayes multinomial model is {} %" . format(recall_score(y_test, MnbPredicts)* 100))


